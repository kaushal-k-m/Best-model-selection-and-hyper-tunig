{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For digits dataset in sklearn.dataset, please try following classifiers and find out the one that gives best performance. Also find the optimal parameters for that classifier. ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params={\n",
    "    'logistic_regression' :{\n",
    "        'model': LogisticRegression(solver='liblinear'),\n",
    "        'params':{\n",
    "            'C' : [1,10,20]\n",
    "        }\n",
    "    },\n",
    "    'decision_tree_classifier' : {\n",
    "        'model' : DecisionTreeClassifier(),\n",
    "        'params' : {\n",
    "            'max_depth' : [1,20,32],\n",
    "            'criterion': ['gini','entropy']\n",
    "        }\n",
    "    },\n",
    "    'random_forest' : {\n",
    "        'model' : RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators':[50,100,150]\n",
    "        }\n",
    "    },\n",
    "    'gaussian_nb' : {\n",
    "        'model' : GaussianNB(),\n",
    "        'params' : {}\n",
    "    },\n",
    "    'multinomial_nb' : {\n",
    "        'model' : MultinomialNB(),\n",
    "        'params' : {}\n",
    "    },\n",
    "    'svm' : {\n",
    "        'model' : svm.SVC(gamma='auto'),\n",
    "        'params' :{\n",
    "            'C':[1,20,30],\n",
    "            'kernel':['rbf','linear'],\n",
    "            'degree' :[1,2,30]\n",
    "        }\n",
    "    }      \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris= load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]\n",
    "for model_name ,mp in model_params.items():\n",
    "    clf=GridSearchCV(mp['model'],mp['params'],cv=5,return_train_score=False)\n",
    "    clf.fit(iris.data,iris.target)\n",
    "    scores.append({\n",
    "        'model' : model_name,\n",
    "        'best_score' : clf.best_score_,\n",
    "        'best_params' : clf.best_params_\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>best_score</th>\n      <th>best_params</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>logistic_regression</td>\n      <td>0.966667</td>\n      <td>{'C': 10}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>decision_tree_classifier</td>\n      <td>0.960000</td>\n      <td>{'criterion': 'gini', 'max_depth': 20}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>random_forest</td>\n      <td>0.966667</td>\n      <td>{'n_estimators': 50}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>gaussian_nb</td>\n      <td>0.953333</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>multinomial_nb</td>\n      <td>0.953333</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>svm</td>\n      <td>0.980000</td>\n      <td>{'C': 1, 'degree': 1, 'kernel': 'rbf'}</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                      model  best_score  \\\n0       logistic_regression    0.966667   \n1  decision_tree_classifier    0.960000   \n2             random_forest    0.966667   \n3               gaussian_nb    0.953333   \n4            multinomial_nb    0.953333   \n5                       svm    0.980000   \n\n                              best_params  \n0                               {'C': 10}  \n1  {'criterion': 'gini', 'max_depth': 20}  \n2                    {'n_estimators': 50}  \n3                                      {}  \n4                                      {}  \n5  {'C': 1, 'degree': 1, 'kernel': 'rbf'}  "
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(scores)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with 'C': 1, 'degree': 1, 'kernel': 'rbf' proves to be the best model with hyper tuning #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}